import asyncio
import hashlib
from datetime import datetime
from typing import Dict, Any, List
import os

from ..core.gemini_client import GeminiClient
from ..core.database import DatabaseManager
from ..utils.file_processor import FileProcessor, ContentValidator

class InfoFlow:
    """å­¸ç¿’è³‡æ–™è™•ç†æµç¨‹"""
    
    def __init__(self, gemini_client: GeminiClient, db_manager: DatabaseManager):
        self.gemini = gemini_client
        self.db = db_manager
        self.data_dir = "./data"
        os.makedirs(self.data_dir, exist_ok=True)
    
    async def process_learning_material(self, raw_text: str) -> Dict[str, Any]:
        """è™•ç†å­¸ç¿’è³‡æ–™çš„å®Œæ•´æµç¨‹"""
        try:
            # æ¸…ç†æ–‡å­—
            cleaned_text = ContentValidator.clean_text(raw_text)
            
            # 1. Summarizer - æ‘˜è¦å…¨æ–‡
            print("æ­£åœ¨ç”Ÿæˆæ‘˜è¦...")
            summary_data = await self.gemini.generate_summary(cleaned_text)
            
            # 2. SubjectClassifier - åˆ†é¡ç§‘ç›®
            print("æ­£åœ¨åˆ†é¡ç§‘ç›®...")
            subject = await self.gemini.classify_subject(cleaned_text)
            
            # 3. Tagger - ç”Ÿæˆæ¨™ç±¤
            print("æ­£åœ¨ç”Ÿæˆæ¨™ç±¤...")
            tags = await self.gemini.generate_tags(cleaned_text, subject)
            
            # 4. QAGenerator - ç”Ÿæˆæ¨¡æ“¬é¡Œ
            print("æ­£åœ¨ç”Ÿæˆæ¨¡æ“¬é¡Œ...")
            questions = await self.gemini.generate_questions(
                summary_data.get('bullets', [])
            )
            
            # 5. StorageAgent - å„²å­˜è³‡æ–™
            print("æ­£åœ¨å„²å­˜è³‡æ–™...")
            result = await self._store_info_data(
                raw_text=raw_text,
                cleaned_text=cleaned_text,
                summary_data=summary_data,
                subject=subject,
                tags=tags,
                questions=questions
            )
            
            return {
                'success': True,
                'type': 'info',
                'subject': subject,
                'document_id': result['document_id'],
                'question_ids': result['question_ids'],
                'file_path': result['file_path'],
                'data': {
                    'summary': summary_data.get('summary', ''),
                    'bullets': summary_data.get('bullets', []),
                    'tags': tags,
                    'questions': questions
                }
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'type': 'info'
            }
    
    async def _store_info_data(self, raw_text: str, cleaned_text: str,
                              summary_data: Dict[str, Any], subject: str,
                              tags: List[str], questions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """å„²å­˜å­¸ç¿’è³‡æ–™"""
        
        # ç”Ÿæˆå”¯ä¸€æª”æ¡ˆåç¨±
        content_hash = hashlib.md5(cleaned_text.encode()).hexdigest()[:8]
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{timestamp}_{content_hash}.md"
        
        # å»ºç«‹ç§‘ç›®ç›®éŒ„
        subject_dir = os.path.join(self.data_dir, subject)
        os.makedirs(subject_dir, exist_ok=True)
        
        file_path = os.path.join(subject_dir, filename)
        
        # ç”Ÿæˆ Markdown å…§å®¹
        markdown_content = self._generate_info_markdown(
            original_text=cleaned_text,
            summary=summary_data.get('summary', ''),
            bullets=summary_data.get('bullets', []),
            tags=tags,
            questions=questions,
            subject=subject
        )
        
        # å„²å­˜ Markdown æª”æ¡ˆ
        FileProcessor.save_markdown(markdown_content, file_path)
        
        # å„²å­˜åˆ°è³‡æ–™åº«
        document_id = self.db.insert_document(
            title=summary_data.get('title', file_path.split('/')[-1] if file_path else 'æœªçŸ¥æ–‡ä»¶'),
            content=raw_text,
            doc_type="info",
            subject=subject,
            file_path=file_path
        )
        
        # å„²å­˜æ¨¡æ“¬é¡Œ
        question_ids = []
        for question in questions:
            question_id = self.db.insert_question(
                document_id=document_id,
                question_text=question.get('stem', ''),
                answer_text=question.get('answer', ''),
                subject=subject
            )
            question_ids.append(question_id)
        
        return {
            'document_id': document_id,
            'question_ids': question_ids,
            'file_path': file_path
        }
    
    def _generate_info_markdown(self, original_text: str, summary: str,
                               bullets: List[str], tags: List[str],
                               questions: List[Dict[str, Any]], subject: str) -> str:
        """ç”Ÿæˆå­¸ç¿’è³‡æ–™çš„ Markdown å…§å®¹"""
        
        content = f"""# ğŸ“– å­¸ç¿’è³‡æ–™è¨˜éŒ„

> **ç§‘ç›®**: `{subject}`  
> **å»ºç«‹æ™‚é–“**: `{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}`  
> **é¡å‹**: `å­¸ç¿’è³‡æ–™`

---

## ğŸ“ å…§å®¹æ‘˜è¦

> **æ‘˜è¦èªªæ˜**: ä»¥ä¸‹æ˜¯ç³»çµ±è‡ªå‹•ç”Ÿæˆçš„å…§å®¹æ‘˜è¦ï¼Œå¹«åŠ©æ‚¨å¿«é€ŸæŒæ¡é‡é»ã€‚

{summary}

---

## ğŸ¯ é‡é»æ•´ç†

"""
        
        if bullets:
            for i, bullet in enumerate(bullets, 1):
                content += f"**{i}.** {bullet}\n\n"
        else:
            content += "*æš«ç„¡é‡é»æ•´ç†*\n\n"
        
        content += "---\n\n## ğŸ§  æ¨¡æ“¬ç·´ç¿’é¡Œ\n\n"
        content += "> **ç·´ç¿’èªªæ˜**: æ ¹æ“šå­¸ç¿’å…§å®¹è‡ªå‹•ç”Ÿæˆçš„ç·´ç¿’é¡Œï¼Œå¹«åŠ©æ‚¨æª¢é©—å­¸ç¿’æˆæœã€‚\n\n"
        
        if questions:
            for i, question in enumerate(questions, 1):
                qtype_map = {
                    'MCQ': 'ğŸ”˜ é¸æ“‡é¡Œ',
                    'TF': 'âœ“ æ˜¯éé¡Œ', 
                    'SA': 'âœï¸ ç°¡ç­”é¡Œ'
                }
                qtype_name = qtype_map.get(question.get('type', 'MCQ'), 'ğŸ”˜ é¸æ“‡é¡Œ')
                
                content += f"### ç¬¬ {i} é¡Œ ({qtype_name})\n\n"
                
                # é¡Œç›®å…§å®¹
                stem = question.get('stem', '').strip()
                if stem:
                    content += f"**ğŸ“‹ é¡Œç›®**:\n```text\n{stem}\n```\n\n"
                
                # ç­”æ¡ˆå…§å®¹
                answer = question.get('answer', '').strip()
                if answer:
                    content += f"**âœ… åƒè€ƒç­”æ¡ˆ**:\n\n{answer}\n\n"
                else:
                    content += f"**âœ… åƒè€ƒç­”æ¡ˆ**: *å¾…è£œå……*\n\n"
                
                if i < len(questions):
                    content += "---\n\n"
        else:
            content += "*æš«ç„¡æ¨¡æ“¬ç·´ç¿’é¡Œ*\n\n"
        
        content += "---\n\n## ğŸ·ï¸ ç›¸é—œæ¨™ç±¤\n\n"
        
        if tags:
            for tag in tags:
                content += f"- `{tag}`\n"
        else:
            content += "*æš«ç„¡ç›¸é—œæ¨™ç±¤*\n"
        
        content += "\n---\n\n## ğŸ“„ åŸå§‹å…§å®¹\n\n"
        content += "> **åŸå§‹è³‡æ–™**: ä»¥ä¸‹æ˜¯æ‚¨è¼¸å…¥çš„åŸå§‹å­¸ç¿’å…§å®¹ï¼Œä¾›åƒè€ƒå°ç…§ã€‚\n\n"
        content += f"```text\n{original_text}\n```\n"
        
        content += f"""
---

<div align="center">
<sub>ğŸ’¡ ç”±è€ƒé¡ŒçŸ¥è­˜æ•´ç†ç³»çµ±è‡ªå‹•ç”Ÿæˆ | ğŸ“… {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}</sub>
</div>"""
        
        return content

class Summarizer:
    """æ‘˜è¦ç”Ÿæˆå™¨ï¼ˆç¨ç«‹çµ„ä»¶ï¼‰"""
    
    def __init__(self, gemini_client: GeminiClient):
        self.gemini = gemini_client
    
    async def generate_summary(self, text: str) -> Dict[str, Any]:
        """ç”Ÿæˆæ‘˜è¦"""
        return await self.gemini.generate_summary(text)

class QAGenerator:
    """æ¨¡æ“¬é¡Œç”Ÿæˆå™¨ï¼ˆç¨ç«‹çµ„ä»¶ï¼‰"""
    
    def __init__(self, gemini_client: GeminiClient):
        self.gemini = gemini_client
    
    async def generate_questions(self, bullets: List[str]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ¨¡æ“¬é¡Œ"""
        return await self.gemini.generate_questions(bullets)

class TypeDetector:
    """é¡å‹åˆ¤å®šå™¨"""
    
    def __init__(self, gemini_client: GeminiClient):
        self.gemini = gemini_client
    
    async def detect_type(self, text: str) -> bool:
        """åˆ¤æ–·æ˜¯å¦ç‚ºè€ƒè©¦é¡Œç›®"""
        return await self.gemini.detect_type(text)
    
    def detect_type_by_keywords(self, text: str) -> bool:
        """åŸºæ–¼é—œéµå­—åˆ¤æ–·æ˜¯å¦ç‚ºè€ƒè©¦é¡Œç›®"""
        exam_keywords = [
            'é¸æ“‡é¡Œ', 'å•ç­”é¡Œ', 'å¡«ç©ºé¡Œ', 'æ˜¯éé¡Œ', 'ç°¡ç­”é¡Œ',
            'ä¸‹åˆ—ä½•è€…', 'è«‹å•', 'è©¦è¿°', 'è§£é‡‹', 'è¨ˆç®—',
            'A)', 'B)', 'C)', 'D)', '(A)', '(B)', '(C)', '(D)',
            'ç­”ï¼š', 'è§£ï¼š', 'ã€ç­”æ¡ˆã€‘', 'æ­£ç¢ºç­”æ¡ˆ',
            'ç¬¬ä¸€é¡Œ', 'ç¬¬äºŒé¡Œ', 'ç¬¬ä¸‰é¡Œ', 'é¡Œç›®'
        ]
        
        text_lower = text.lower()
        chinese_text = text
        
        # æª¢æŸ¥é—œéµå­—
        keyword_count = 0
        for keyword in exam_keywords:
            if keyword in chinese_text or keyword.lower() in text_lower:
                keyword_count += 1
        
        # å¦‚æœåŒ…å«2å€‹ä»¥ä¸Šè€ƒè©¦ç›¸é—œé—œéµå­—ï¼Œèªç‚ºæ˜¯è€ƒé¡Œ
        return keyword_count >= 2

class ContentProcessor:
    """å…§å®¹è™•ç†å™¨çµ±ä¸€ä»‹é¢"""
    
    def __init__(self, gemini_client: GeminiClient, db_manager: DatabaseManager):
        self.gemini = gemini_client
        self.db = db_manager
        self.type_detector = TypeDetector(gemini_client)
        self.answer_flow = None  # å»¶é²å°å…¥é¿å…å¾ªç’°å°å…¥
        self.info_flow = InfoFlow(gemini_client, db_manager)
    
    async def process_content(self, text: str) -> Dict[str, Any]:
        """çµ±ä¸€è™•ç†å…§å®¹"""
        try:
            # åˆ¤æ–·å…§å®¹é¡å‹
            is_exam = await self.type_detector.detect_type(text)
            
            if is_exam:
                # å»¶é²å°å…¥ AnswerFlow
                if self.answer_flow is None:
                    from .answer_flow import AnswerFlow
                    self.answer_flow = AnswerFlow(self.gemini, self.db)
                
                return await self.answer_flow.process_exam_question(text)
            else:
                return await self.info_flow.process_learning_material(text)
                
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'type': 'unknown'
            }
