import asyncio
import hashlib
from datetime import datetime
from typing import Dict, Any, List
import os

from ..core.gemini_client import GeminiClient
from ..core.database import DatabaseManager
from ..utils.file_processor import FileProcessor, ContentValidator

class AnswerFlow:
    """è€ƒé¡Œè™•ç†æµç¨‹"""
    
    def __init__(self, gemini_client: GeminiClient, db_manager: DatabaseManager):
        self.gemini = gemini_client
        self.db = db_manager
        self.data_dir = "./data"
        os.makedirs(self.data_dir, exist_ok=True)
    
    async def process_exam_question(self, raw_text: str) -> Dict[str, Any]:
        """è™•ç†è€ƒè©¦é¡Œç›®çš„å®Œæ•´æµç¨‹"""
        try:
            # æ¸…ç†æ–‡å­—
            cleaned_text = ContentValidator.clean_text(raw_text)
            
            # åˆ¤æ–·æ˜¯å¦ç‚ºå®Œæ•´è€ƒå·ï¼ˆåŒ…å«å¤šé¡Œï¼‰
            is_exam_paper = await self._is_exam_paper(cleaned_text)
            
            if is_exam_paper:
                return await self._process_exam_paper(raw_text, cleaned_text)
            else:
                return await self._process_single_question(raw_text, cleaned_text)
                
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'type': 'exam'
            }
    
    async def _is_exam_paper(self, text: str) -> bool:
        """åˆ¤æ–·æ˜¯å¦ç‚ºåŒ…å«å¤šé¡Œçš„è€ƒå·"""
        # æª¢æŸ¥å¸¸è¦‹çš„é¡Œç›®æ¨™è¨˜
        chinese_numbers = ['ä¸€ã€', 'äºŒã€', 'ä¸‰ã€', 'å››ã€', 'äº”ã€', 'å…­ã€', 'ä¸ƒã€', 'å…«ã€', 'ä¹ã€', 'åã€']
        arabic_numbers = ['1.', '2.', '3.', '4.', '5.', '6.', '7.', '8.', '9.', '10.']
        parenthesis_numbers = ['ï¼ˆä¸€ï¼‰', 'ï¼ˆäºŒï¼‰', 'ï¼ˆä¸‰ï¼‰', 'ï¼ˆå››ï¼‰', 'ï¼ˆäº”ï¼‰', 'ï¼ˆå…­ï¼‰']
        question_numbers = ['ç¬¬ä¸€é¡Œ', 'ç¬¬äºŒé¡Œ', 'ç¬¬ä¸‰é¡Œ', 'ç¬¬å››é¡Œ', 'ç¬¬äº”é¡Œ']
        english_numbers = ['Q1', 'Q2', 'Q3', 'Q4', 'Q5']
        
        all_markers = chinese_numbers + arabic_numbers + parenthesis_numbers + question_numbers + english_numbers
        
        marker_count = 0
        for marker in all_markers:
            if marker in text:
                marker_count += 1
        
        # å¦‚æœæ‰¾åˆ°2å€‹æˆ–ä»¥ä¸Šçš„é¡Œç›®æ¨™è¨˜ï¼Œèªç‚ºæ˜¯è€ƒå·
        return marker_count >= 2
    
    async def _process_exam_paper(self, raw_text: str, cleaned_text: str) -> Dict[str, Any]:
        """è™•ç†å®Œæ•´è€ƒå·ï¼ˆå¤šé¡Œï¼‰"""
        try:
            print("åµæ¸¬åˆ°å®Œæ•´è€ƒå·ï¼Œæ­£åœ¨è‡ªå‹•åˆ†é¡Œ...")
            
            # 1. è‡ªå‹•åˆ†é¡Œ
            questions_data = await self.gemini.split_exam_paper(cleaned_text)
            
            if not questions_data:
                return {
                    'success': False,
                    'error': 'ç„¡æ³•è‡ªå‹•åˆ†å‰²è€ƒå·é¡Œç›®',
                    'type': 'exam'
                }
            
            # 2. ç§‘ç›®åˆ†é¡
            print("æ­£åœ¨åˆ†é¡ç§‘ç›®...")
            subject = await self.gemini.classify_subject(cleaned_text)
            
            # 3. å„²å­˜è€ƒå·æ–‡ä»¶
            result = await self._store_exam_paper_data(
                raw_text=raw_text,
                cleaned_text=cleaned_text,
                questions_data=questions_data,
                subject=subject
            )
            
            return {
                'success': True,
                'type': 'exam_paper',
                'subject': subject,
                'document_id': result['document_id'],
                'question_ids': result['question_ids'],
                'file_path': result['file_path'],
                'questions_count': len(questions_data),
                'data': {
                    'questions': questions_data,
                    'subject': subject
                }
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'è€ƒå·è™•ç†å¤±æ•—: {str(e)}',
                'type': 'exam_paper'
            }
    
    async def _process_single_question(self, raw_text: str, cleaned_text: str) -> Dict[str, Any]:
        """è™•ç†å–®ä¸€é¡Œç›®"""
        # 1. AnswerGenerator - ç”Ÿæˆæ¨™æº–ç­”æ¡ˆ
        print("æ­£åœ¨ç”Ÿæˆæ¨™æº–ç­”æ¡ˆ...")
        answer_data = await self.gemini.generate_answer(cleaned_text)
        
        # 2. Highlighter - æ­¸ç´é‡é»
        print("æ­£åœ¨æ­¸ç´é‡é»...")
        highlights = await self.gemini.generate_highlights(cleaned_text)
        
        # 3. SubjectClassifier - åˆ†é¡ç§‘ç›®
        print("æ­£åœ¨åˆ†é¡ç§‘ç›®...")
        subject = await self.gemini.classify_subject(cleaned_text)
        
        # 4. Tagger - ç”Ÿæˆæ¨™ç±¤
        print("æ­£åœ¨ç”Ÿæˆæ¨™ç±¤...")
        tags = await self.gemini.generate_tags(cleaned_text, subject)
        
        # 5. StorageAgent - å„²å­˜è³‡æ–™
        print("æ­£åœ¨å„²å­˜è³‡æ–™...")
        result = await self._store_exam_data(
            raw_text=raw_text,
            cleaned_text=cleaned_text,
            answer_data=answer_data,
            highlights=highlights,
            subject=subject,
            tags=tags
        )
        
        return {
            'success': True,
            'type': 'exam',
            'subject': subject,
            'document_id': result['document_id'],
            'question_id': result['question_id'],
            'file_path': result['file_path'],
            'data': {
                'stem': cleaned_text,
                'answer': answer_data.get('answer', ''),
                'sources': answer_data.get('sources', []),
                'highlights': highlights,
                'tags': tags
            }
        }
    
    async def _store_exam_data(self, raw_text: str, cleaned_text: str,
                              answer_data: Dict[str, Any], highlights: List[str],
                              subject: str, tags: List[str]) -> Dict[str, Any]:
        """å„²å­˜è€ƒé¡Œè³‡æ–™"""
        
        # ç”Ÿæˆå”¯ä¸€æª”æ¡ˆåç¨±
        content_hash = hashlib.md5(cleaned_text.encode()).hexdigest()[:8]
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{timestamp}_{content_hash}.md"
        
        # å»ºç«‹ç§‘ç›®ç›®éŒ„
        subject_dir = os.path.join(self.data_dir, subject)
        os.makedirs(subject_dir, exist_ok=True)
        
        file_path = os.path.join(subject_dir, filename)
        
        # ç”Ÿæˆ Markdown å…§å®¹
        markdown_content = self._generate_exam_markdown(
            stem=cleaned_text,
            answer=answer_data.get('answer', ''),
            sources=answer_data.get('sources', []),
            highlights=highlights,
            tags=tags,
            subject=subject
        )
        
        # å„²å­˜ Markdown æª”æ¡ˆ
        FileProcessor.save_markdown(markdown_content, file_path)
        
        # å„²å­˜åˆ°è³‡æ–™åº«
        document_id = self.db.insert_document(
            title=answer_data.get('question', 'æœªçŸ¥å•é¡Œ')[:100],
            content=raw_text,
            doc_type="exam",
            subject=subject,
            file_path=file_path
        )
        
        question_id = self.db.insert_question(
            document_id=document_id,
            question_text=answer_data.get('question', cleaned_text),
            answer_text=answer_data.get('answer', ''),
            subject=subject
        )
        
        return {
            'document_id': document_id,
            'question_id': question_id,
            'file_path': file_path
        }
    
    async def _store_exam_paper_data(self, raw_text: str, cleaned_text: str,
                                   questions_data: List[Dict[str, Any]], subject: str) -> Dict[str, Any]:
        """å„²å­˜è€ƒå·è³‡æ–™ï¼ˆå¤šé¡Œï¼‰"""
        
        # ç”Ÿæˆå”¯ä¸€æª”æ¡ˆåç¨±
        content_hash = hashlib.md5(cleaned_text.encode()).hexdigest()[:8]
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"exam_paper_{timestamp}_{content_hash}.md"
        
        # å»ºç«‹ç§‘ç›®ç›®éŒ„
        subject_dir = os.path.join(self.data_dir, subject)
        os.makedirs(subject_dir, exist_ok=True)
        
        file_path = os.path.join(subject_dir, filename)
        
        # ç”Ÿæˆ Markdown å…§å®¹
        markdown_content = self._generate_exam_paper_markdown(
            questions_data=questions_data,
            subject=subject
        )
        
        # å„²å­˜ Markdown æª”æ¡ˆ
        FileProcessor.save_markdown(markdown_content, file_path)
        
        # å„²å­˜åˆ°è³‡æ–™åº«
        document_id = self.db.insert_document(
            title=f"è€ƒå·ï¼ˆå…±{len(questions_data)}é¡Œï¼‰",
            content=raw_text,
            doc_type="exam",
            subject=subject,
            file_path=file_path
        )
        
        # å„²å­˜æ¯å€‹é¡Œç›®
        question_ids = []
        for i, question_data in enumerate(questions_data):
            # ä½¿ç”¨ stem æ¬„ä½ï¼Œå¦‚æœæ²’æœ‰å‰‡å›é€€åˆ° question æ¬„ä½
            question_text = question_data.get('stem', question_data.get('question', ''))
            answer_text = question_data.get('answer', '')
            
            question_id = self.db.insert_question(
                document_id=document_id,
                question_text=question_text,
                answer_text=answer_text,
                subject=subject
            )
            question_ids.append(question_id)
        
        return {
            'document_id': document_id,
            'question_ids': question_ids,
            'file_path': file_path
        }
    
    def _generate_exam_paper_markdown(self, questions_data: List[Dict[str, Any]], subject: str) -> str:
        """ç”Ÿæˆè€ƒå·çš„ Markdown å…§å®¹"""
        
        total_questions = len(questions_data)
        content = f"""# ğŸ“ è€ƒå·è¨˜éŒ„

> **ç§‘ç›®**: `{subject}`  
> **å»ºç«‹æ™‚é–“**: `{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}`  
> **é¡å‹**: `è€ƒå·ï¼ˆå…± {total_questions} é¡Œï¼‰`

---

## ğŸ“Š é¡Œç›®æ¦‚è¦½

| é¡Œè™Ÿ | é¡Œå‹ | ç‹€æ…‹ |
|------|------|------|
"""
        
        # ç”Ÿæˆé¡Œç›®æ¦‚è¦½è¡¨æ ¼
        for i, question in enumerate(questions_data, 1):
            number = question.get('number', f'ç¬¬{i}é¡Œ')
            q_type = question.get('type', 'æœªåˆ†é¡')
            status = 'âœ… å·²è§£ç­”' if question.get('answer') else 'â³ å¾…è§£ç­”'
            content += f"| {number} | {q_type} | {status} |\n"
        
        content += "\n---\n\n## ğŸ“š é¡Œç›®å…§å®¹\n\n"
        
        for i, question in enumerate(questions_data, 1):
            number = question.get('number', f'ç¬¬{i}é¡Œ')
            content += f"### {i}. {number}\n\n"
            
            # é¡Œç›®å…§å®¹ - ä½¿ç”¨ stem æ¬„ä½
            stem = question.get('stem', question.get('question', '')).strip()
            if stem:
                content += f"**ğŸ“‹ é¡Œç›®**:\n\n{stem}\n\n"
            
            # ç­”æ¡ˆå…§å®¹
            answer = question.get('answer', '').strip()
            if answer:
                content += f"**âœ… æ¨™æº–ç­”æ¡ˆ**:\n\n{answer}\n\n"
            else:
                content += f"**â³ æ¨™æº–ç­”æ¡ˆ**: *å¾…è£œå……*\n\n"
            
            # é¡Œå‹æ¨™è¨˜
            q_type = question.get('type', 'æœªåˆ†é¡')
            content += f"**ğŸ·ï¸ é¡Œå‹**: `{q_type}`\n\n"
            
            # åˆ†éš”ç·š
            if i < len(questions_data):
                content += "---\n\n"
        
        content += f"""
---

<div align="center">
<sub>ğŸ’¡ ç”±è€ƒé¡ŒçŸ¥è­˜æ•´ç†ç³»çµ±è‡ªå‹•ç”Ÿæˆ | ğŸ“… {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}</sub>
</div>"""
        
        return content
    
    def _generate_exam_markdown(self, stem: str, answer: str, sources: List[str],
                               highlights: List[str], tags: List[str], subject: str) -> str:
        """ç”Ÿæˆè€ƒé¡Œçš„ Markdown å…§å®¹"""
        
        content = f"""# ğŸ“š è€ƒé¡Œè¨˜éŒ„

> **ç§‘ç›®**: `{subject}`  
> **å»ºç«‹æ™‚é–“**: `{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}`  
> **é¡å‹**: `è€ƒè©¦é¡Œç›®`

---

## ğŸ“‹ é¡Œç›®

```text
{stem}
```

---

## âœ… æ¨™æº–ç­”æ¡ˆ

{answer}

---

## ğŸ¯ é‡é»æ‘˜è¦

"""
        
        if highlights:
            for i, highlight in enumerate(highlights, 1):
                content += f"**{i}.** {highlight}\n\n"
        else:
            content += "*æš«ç„¡é‡é»æ‘˜è¦*\n\n"
        
        content += "---\n\n## ğŸ“– åƒè€ƒä¾†æº\n\n"
        
        if sources:
            for i, source in enumerate(sources, 1):
                content += f"**{i}.** {source}\n"
        else:
            content += "*æš«ç„¡åƒè€ƒä¾†æº*\n"
        
        content += "\n---\n\n## ğŸ·ï¸ ç›¸é—œæ¨™ç±¤\n\n"
        
        if tags:
            for tag in tags:
                content += f"- `{tag}`\n"
        else:
            content += "*æš«ç„¡ç›¸é—œæ¨™ç±¤*\n"
        
        content += f"""
---

<div align="center">
<sub>ğŸ’¡ ç”±è€ƒé¡ŒçŸ¥è­˜æ•´ç†ç³»çµ±è‡ªå‹•ç”Ÿæˆ | ğŸ“… {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}</sub>
</div>"""
        
        return content

class AnswerGenerator:
    """ç­”æ¡ˆç”Ÿæˆå™¨ï¼ˆç¨ç«‹çµ„ä»¶ï¼‰"""
    
    def __init__(self, gemini_client: GeminiClient):
        self.gemini = gemini_client
    
    async def generate(self, question_text: str) -> Dict[str, Any]:
        """ç”Ÿæˆæ¨™æº–ç­”æ¡ˆ"""
        return await self.gemini.generate_answer(question_text)

class Highlighter:
    """é‡é»æ­¸ç´å™¨ï¼ˆç¨ç«‹çµ„ä»¶ï¼‰"""
    
    def __init__(self, gemini_client: GeminiClient):
        self.gemini = gemini_client
    
    async def generate_highlights(self, text: str) -> List[str]:
        """æ­¸ç´é‡é»"""
        return await self.gemini.generate_highlights(text)

class SubjectClassifier:
    """ç§‘ç›®åˆ†é¡å™¨ï¼ˆç¨ç«‹çµ„ä»¶ï¼‰"""
    
    def __init__(self, gemini_client: GeminiClient):
        self.gemini = gemini_client
    
    async def classify(self, text: str) -> str:
        """åˆ†é¡ç§‘ç›®"""
        return await self.gemini.classify_subject(text)

class Tagger:
    """æ¨™ç±¤ç”Ÿæˆå™¨ï¼ˆç¨ç«‹çµ„ä»¶ï¼‰"""
    
    def __init__(self, gemini_client: GeminiClient):
        self.gemini = gemini_client
    
    async def generate_tags(self, text: str, subject: str) -> List[str]:
        """ç”Ÿæˆæ¨™ç±¤"""
        return await self.gemini.generate_tags(text, subject)

class StorageAgent:
    """å„²å­˜ä»£ç†ï¼ˆç¨ç«‹çµ„ä»¶ï¼‰"""
    
    def __init__(self, db_manager: DatabaseManager, data_dir: str = "./data"):
        self.db = db_manager
        self.data_dir = data_dir
        os.makedirs(data_dir, exist_ok=True)
    
    def store_exam_document(self, **kwargs) -> Dict[str, Any]:
        """å„²å­˜è€ƒé¡Œæ–‡ä»¶"""
        # å¯¦ä½œå„²å­˜é‚è¼¯
        pass
