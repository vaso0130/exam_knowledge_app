from typing import Dict, Any, List
import asyncio
import concurrent.futures
from src.core.gemini_client import GeminiClient
from src.core.database import DatabaseManager
import json

class ContentFlow:
    """å…§å®¹è™•ç†æµç¨‹ç®¡ç†å™¨ - çµ±ä¸€ç®¡ç†æ‰€æœ‰å…§å®¹åˆ†æã€å•é¡Œç”Ÿæˆå’ŒçŸ¥è­˜é»é—œè¯"""
    
    def __init__(self, gemini_client: GeminiClient, db_manager: DatabaseManager):
        self.gemini = gemini_client
        self.db = db_manager
        from ..utils.file_processor import FileProcessor
        self.file_processor = FileProcessor()

    @staticmethod
    def _sanitize_question_text(text: str) -> str:
        """ç§»é™¤å¯èƒ½åŒ…å«è§£ç­”æˆ–èªªæ˜æ¨™é¡Œçš„è¡Œ"""
        if not text:
            return text
        import re
        pattern = re.compile(r"^\s*(ç­”æ¡ˆ|è§£ç­”|åƒè€ƒç­”æ¡ˆ|å»ºè­°|èªªæ˜|è§£æ)[\s:ï¼š]", re.I)
        lines = [line for line in text.splitlines() if not pattern.match(line)]
        return "\n".join(lines).strip()

    @staticmethod
    def _convert_markdown_to_html_with_code_blocks(md_text: str) -> str:
        """
        Converts Markdown text to HTML, specifically handling fenced code blocks
        to include Prism.js compatible classes.
        """
        return markdown.markdown(md_text, extensions=['fenced_code', 'nl2br', 'tables'])
    
    def process_file(self, file_path: str, filename: str, suggested_subject: str = None) -> Dict[str, Any]:
        """è™•ç†æª”æ¡ˆçš„çµ±ä¸€å…¥å£é»"""
        try:
            content, _ = self.file_processor.process_input(file_path)
            return self.complete_ai_processing(content, filename, suggested_subject)
        except Exception as e:
            print(f"è™•ç†æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return {'success': False, 'error': str(e), 'message': f'æª”æ¡ˆè™•ç†å¤±æ•—: {str(e)}'}
    
    def complete_ai_processing(self, content: str, filename: str, suggested_subject: str = None, source_url: str = None) -> Dict[str, Any]:
        """å®Œæ•´ AI è™•ç†æµç¨‹"""
        try:
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(asyncio.run, self._run_async_processing(content, filename, suggested_subject, source_url))
                return future.result()
        except Exception as e:
            print(f"å®Œæ•´ AI è™•ç†æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return {'success': False, 'error': str(e), 'message': 'è™•ç†å¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦'}
    
    def _extract_answer_string(self, answer_data: Any) -> str:
        """Recursively extracts the answer string from potentially nested answer_data."""
        if isinstance(answer_data, dict):
            if 'answer' in answer_data:
                return self._extract_answer_string(answer_data['answer'])
            else:
                return json.dumps(answer_data, ensure_ascii=False)
        elif isinstance(answer_data, list):
            return json.dumps(answer_data, ensure_ascii=False)
        else:
            return str(answer_data)

    async def _run_async_processing(self, content: str, filename: str, suggested_subject: str = None, source_url: str = None) -> Dict[str, Any]:
        """åŸ·è¡Œç•°æ­¥è™•ç†æµç¨‹"""
        try:
            print("ğŸ¤– AI æ­£åœ¨åˆ†æå…§å®¹é¡å‹...")
            parsed_data = await self.gemini.parse_exam_paper(content)
            
            content_type = parsed_data.get('content_type', 'study_material')
            detected_subject = parsed_data.get('subject', suggested_subject or 'å…¶ä»–')
            
            print(f"ğŸ“‹ å…§å®¹åˆ†é¡çµæœï¼š{content_type} ({detected_subject})")
            
            doc_id = self.db.add_document(
                title=filename, 
                content=content, 
                subject=detected_subject, 
                original_content=content,
                source=source_url
            )
            
            if content_type == 'exam_paper':
                print("ğŸ“ æª¢æ¸¬åˆ°è€ƒé¡Œå…§å®¹ï¼ŒåŸ·è¡Œè€ƒé¡Œè™•ç†æµç¨‹...")
                result = await self._process_exam_content(content, detected_subject, doc_id, parsed_data)
            else:
                print("ğŸ“š æª¢æ¸¬åˆ°å­¸ç¿’è³‡æ–™ï¼ŒåŸ·è¡Œå­¸ç¿’è³‡æ–™è™•ç†æµç¨‹...")
                result = await self._process_study_material(content, detected_subject, doc_id, parsed_data)
            
            if result.get('success'):
                print("ğŸ—ºï¸ æ­£åœ¨ç”Ÿæˆå¿ƒæ™ºåœ–...")
                all_kps = result.get('knowledge_points', [])
                if all_kps:
                    mindmap_data = await self.gemini.generate_mindmap(detected_subject, all_kps)
                    if mindmap_data:
                        self.db.update_document_mindmap(doc_id, mindmap_data)
                        print(f"âœ… å¿ƒæ™ºåœ–å·²æˆåŠŸç”Ÿæˆä¸¦å„²å­˜è‡³æ–‡æª” {doc_id}")
                        result['mindmap'] = mindmap_data
            
            return result
                
        except Exception as e:
            print(f"ç•°æ­¥è™•ç†æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise e
    
    async def _process_exam_content(self, content: str, subject: str, doc_id: int, parsed_data: Dict) -> Dict[str, Any]:
        """è€ƒé¡Œè™•ç†æµç¨‹"""
        questions = parsed_data.get('questions', [])
        saved_questions = []
        all_knowledge_points = set()
        
        print(f"ğŸ“ é–‹å§‹è™•ç† {len(questions)} é“è€ƒé¡Œ...")
        
        for i, question_data in enumerate(questions, 1):
            try:
                question_text = self._sanitize_question_text(question_data.get('stem', ''))
                if not question_text:
                    continue

                # ç›´æ¥ä½¿ç”¨ç´”æ·¨çš„é¡Œå¹¹ç”Ÿæˆç­”æ¡ˆ
                answer_data = await self.gemini.generate_answer(question_text)
                print(f"DEBUG: answer_data type: {type(answer_data)}, value: {answer_data}")
                answer_text = self._extract_answer_string(answer_data)
                print(f"DEBUG: answer_text type: {type(answer_text)}, value: {answer_text}")
                
                question_id = self.db.insert_question(
                    document_id=doc_id,
                    title=question_data.get('title', f'é¡Œç›® {i}'),
                    question_text=question_text,
                    answer_text=answer_text,
                    subject=subject,
                    difficulty=question_data.get('difficulty'),
                    guidance_level=question_data.get('guidance_level')
                )
                print(f"DEBUG: Difficulty: {question_data.get('difficulty')}, Guidance Level: {question_data.get('guidance_level')}")
                
                knowledge_points = question_data.get('knowledge_points', [])
                for kp_name in knowledge_points:
                    kp_id = self.db.add_knowledge_point(kp_name.strip(), subject)
                    self.db.link_question_to_knowledge_point(question_id, kp_id)
                    all_knowledge_points.add(kp_name.strip())
                
                saved_questions.append({
                    'id': question_id,
                    'stem': question_text,
                    'answer': answer_text,
                    'knowledge_points': knowledge_points
                })
            except Exception as e:
                print(f"    è™•ç†ç¬¬ {i} é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                continue
        
        return {
            'success': True,
            'content_type': 'exam_paper',
            'subject': subject,
            'document_id': doc_id,
            'questions': saved_questions,
            'knowledge_points': list(all_knowledge_points),
            'message': f'æˆåŠŸè™•ç†è€ƒé¡Œï¼Œè§£æäº† {len(saved_questions)} é“é¡Œç›®ã€‚'
        }

    async def _process_study_material(self, content: str, subject: str, doc_id: int, parsed_data: Dict) -> Dict[str, Any]:
        """å­¸ç¿’è³‡æ–™è™•ç†æµç¨‹"""
        print("ğŸ“š åŸ·è¡Œå­¸ç¿’è³‡æ–™è™•ç†æµç¨‹...")
        
        # ç”Ÿæˆæ¨¡æ“¬é¡Œ
        generated_questions = await self.gemini.generate_questions_from_text(content, subject)
        saved_questions = []
        all_knowledge_points = set()

        for q_data in generated_questions:
            question_id = self.db.insert_question(
                document_id=doc_id,
                title=q_data.get('title', 'æ¨¡æ“¬é¡Œ'),
                question_text=q_data.get('question', ''),
                answer_text=self._extract_answer_string(q_data.get('answer', '')),
                subject=subject,
                difficulty=q_data.get('difficulty'),
            )
            saved_questions.append({'id': question_id, **q_data})
            
            for kp_name in q_data.get('knowledge_points', []):
                kp_id = self.db.add_knowledge_point(kp_name.strip(), subject)
                self.db.link_question_to_knowledge_point(question_id, kp_id)
                all_knowledge_points.add(kp_name.strip())

        # ç”Ÿæˆæ‘˜è¦å’Œæ¸¬é©—
        summary_data = await self.gemini.generate_summary(content)
        quiz_data = await self.gemini.generate_quick_quiz(content, subject)

        # å„²å­˜æ‘˜è¦å’Œæ¸¬é©—
        summary_text = json.dumps(summary_data, ensure_ascii=False) if summary_data else None
        quiz_text = json.dumps(quiz_data, ensure_ascii=False) if quiz_data else None
        self.db.update_document_summary_and_quiz(doc_id, summary_text, quiz_text)

        return {
            'success': True,
            'content_type': 'study_material',
            'subject': subject,
            'document_id': doc_id,
            'questions': saved_questions,
            'knowledge_points': list(all_knowledge_points),
            'summary': summary_data,
            'quiz': quiz_data,
            'message': f'å­¸ç¿’è³‡æ–™è™•ç†å®Œæˆï¼ç”Ÿæˆäº† {len(saved_questions)} é“æ¨¡æ“¬é¡Œã€‚'
        }