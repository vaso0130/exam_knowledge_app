from typing import Dict, Any
import asyncio
import concurrent.futures
from src.core.gemini_client import GeminiClient
from src.core.database import DatabaseManager
import json
from ..utils.markdown_utils import (
    format_code_blocks,
    format_summary_to_markdown,
    format_answer_text,
    detect_and_fence_indented_code,
)
from ..flows.mindmap_flow import MindmapFlow

class ContentFlow:
    """å…§å®¹è™•ç†æµç¨‹ç®¡ç†å™¨ - çµ±ä¸€ç®¡ç†æ‰€æœ‰å…§å®¹åˆ†æã€å•é¡Œç”Ÿæˆå’ŒçŸ¥è­˜é»é—œè¯"""
    
    def __init__(self, gemini_client: GeminiClient, db_manager: DatabaseManager):
        self.gemini = gemini_client
        self.db = db_manager
        from ..utils.file_processor import FileProcessor
        self.file_processor = FileProcessor()
        self.mindmap_flow = MindmapFlow(gemini_client, db_manager)

    @staticmethod
    def _sanitize_question_text(text: str) -> str:
        """ç§»é™¤å¯èƒ½åŒ…å«è§£ç­”æˆ–èªªæ˜æ¨™é¡Œçš„è¡Œï¼Œä½†ä¿ç•™ç¨‹å¼ç¢¼å€å¡Šå…§çš„å…§å®¹"""
        if not text:
            return text
        import re
        pattern = re.compile(r"^\s*(ç­”æ¡ˆ|è§£ç­”|åƒè€ƒç­”æ¡ˆ|å»ºè­°|èªªæ˜|è§£æ)[\s:ï¼š]", re.I)
        lines = text.splitlines()
        sanitized_lines = []
        in_code_block = False

        for line in lines:
            if line.strip().startswith("```"):
                in_code_block = not in_code_block
                sanitized_lines.append(line)
            elif in_code_block:
                sanitized_lines.append(line)
            elif not pattern.match(line):
                sanitized_lines.append(line)

        cleaned = "\n".join(sanitized_lines).strip()
        return detect_and_fence_indented_code(cleaned)

    
    
    def process_file(self, file_path: str, filename: str, suggested_subject: str = None) -> Dict[str, Any]:
        """è™•ç†æª”æ¡ˆçš„çµ±ä¸€å…¥å£é»"""
        try:
            # content is the extracted text from the file
            content, _ = self.file_processor.process_input(file_path)

            # ======================================================================
            # â–¼â–¼â–¼ DEBUG CHECKPOINT 1: æª¢æŸ¥ FileProcessor çš„è¼¸å‡º â–¼â–¼â–¼
            print("\n" + "="*20 + " DEBUG CHECKPOINT 1: AFTER FileProcessor " + "="*20)
            print("--- Raw content extracted from file ---")
            print(content)
            print("="*67 + "\n")
            # â–²â–²â–² DEBUG CHECKPOINT 1 â–²â–²â–²
            # ======================================================================

            # Pass the file_path along with the extracted content
            return self.complete_ai_processing(content, filename, suggested_subject, file_path=file_path)
        except Exception as e:
            print(f"è™•ç†æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return {'success': False, 'error': str(e), 'message': f'æª”æ¡ˆè™•ç†å¤±æ•—: {str(e)}'}
    
    def complete_ai_processing(self, content: str, filename: str, suggested_subject: str = None, source_url: str = None, file_path: str = None) -> Dict[str, Any]:
        """å®Œæ•´ AI è™•ç†æµç¨‹"""
        try:
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(asyncio.run, self._run_async_processing(content, filename, suggested_subject, source_url, file_path))
                return future.result()
        except Exception as e:
            print(f"å®Œæ•´ AI è™•ç†æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return {'success': False, 'error': str(e), 'message': 'è™•ç†å¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦'}
    
    def _extract_answer_string(self, answer_data: Any) -> str:
        """Recursively extracts the answer string from potentially nested answer_data."""
        if isinstance(answer_data, dict):
            if 'answer' in answer_data:
                extracted_answer = self._extract_answer_string(answer_data['answer'])
                if not extracted_answer or "not included in the prompt" in extracted_answer.lower() or "answer is not provided" in extracted_answer.lower():
                    return "ï¼ˆåƒè€ƒç­”æ¡ˆç”Ÿæˆå¤±æ•—æˆ–æœªæä¾›ï¼Œè«‹æª¢æŸ¥åŸå§‹è³‡æ–™æˆ–ç¨å¾Œé‡è©¦ã€‚ï¼‰"
                return extracted_answer
            else:
                return json.dumps(answer_data, ensure_ascii=False)
        elif isinstance(answer_data, list):
            return json.dumps(answer_data, ensure_ascii=False)
        else:
            extracted_answer = str(answer_data)
            if not extracted_answer or "not included in the prompt" in extracted_answer.lower() or "answer is not provided" in extracted_answer.lower():
                return "ï¼ˆåƒè€ƒç­”æ¡ˆç”Ÿæˆå¤±æ•—æˆ–æœªæä¾›ï¼Œè«‹æª¢æŸ¥åŸå§‹è³‡æ–™æˆ–ç¨å¾Œé‡è©¦ã€‚ï¼‰"
            return extracted_answer

    async def _run_async_processing(self, content: str, filename: str, suggested_subject: str = None, source_url: str = None, file_path: str = None) -> Dict[str, Any]:
        """åŸ·è¡Œç•°æ­¥è™•ç†æµç¨‹"""
        try:
            print("ğŸ¤– AI æ­£åœ¨åˆ†æå…§å®¹é¡å‹...")
            parsed_data = await self.gemini.parse_exam_paper(content)

            # # ======================================================================
            # # â–¼â–¼â–¼ DEBUG CHECKPOINT 2 (å·²ä¿®æ­£) â–¼â–¼â–¼
            # print("\n" + "="*20 + " DEBUG CHECKPOINT 2: AFTER parse_exam_paper " + "="*20)
            # print("--- Full parsed_data from AI ---")
            # print(json.dumps(parsed_data, indent=2, ensure_ascii=False))
            # # ä¿®æ­£ï¼šè¿­ä»£ questions åˆ—è¡¨ä¾†å°å‡ºæ¯å€‹ stem
            # if parsed_data.get('questions'):
            #     for i, q_data in enumerate(parsed_data['questions']):
            #         stem_text = q_data.get('stem', 'STEM NOT FOUND')
            #         print(f"\n--- Extracted 'stem' from Question {i+1} ---")
            #         print(stem_text)
            # print("="*70 + "\n")
            # # â–²â–²â–² DEBUG CHECKPOINT 2 (å·²ä¿®æ­£) â–²â–²â–²
            # # ======================================================================
            
            content_type = parsed_data.get('content_type', 'study_material')
            detected_subject = parsed_data.get('subject', suggested_subject or 'å…¶ä»–')
            
            print(f"ğŸ“‹ å…§å®¹åˆ†é¡çµæœï¼š{content_type} ({detected_subject})")
            
            doc_id = self.db.add_document(
                title=filename, 
                content=content, # Extracted text
                subject=detected_subject, 
                source=source_url,
                file_path=file_path # The actual file path
            )
            
            if content_type == 'exam_paper':
                print("ğŸ“ æª¢æ¸¬åˆ°è€ƒé¡Œå…§å®¹ï¼ŒåŸ·è¡Œè€ƒé¡Œè™•ç†æµç¨‹...")
                result = await self._process_exam_content(content, detected_subject, doc_id, parsed_data)
            else:
                print("ğŸ“š æª¢æ¸¬åˆ°å­¸ç¿’è³‡æ–™ï¼ŒåŸ·è¡Œå­¸ç¿’è³‡æ–™è™•ç†æµç¨‹...")
                result = await self._process_study_material(content, detected_subject, doc_id, parsed_data)
            
            if result.get('success'):
                return result
            else:
                return result
                
        except Exception as e:
            print(f"ç•°æ­¥è™•ç†æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise e
    
    async def _process_exam_content(self, content: str, subject: str, doc_id: int, parsed_data: Dict) -> Dict[str, Any]:
            """è€ƒé¡Œè™•ç†æµç¨‹"""
            questions = parsed_data.get('questions', [])
            saved_questions = []
            all_knowledge_points = set()
            
            print(f"ğŸ“ é–‹å§‹è™•ç† {len(questions)} é“è€ƒé¡Œ...")
            
            for i, question_data in enumerate(questions, 1):
                try:
                    # æ­¥é©Ÿ 1: ç›´æ¥ä½¿ç”¨ AI ç”¢ç”Ÿçš„ã€å·²å®Œç¾æ ¼å¼åŒ–çš„é¡Œç›® (stem)
                    question_text = question_data.get('stem', '')
                    
                    if not question_text:
                        continue

                    # æ­¥é©Ÿ 2: è®“ AI é‡å°é€™å€‹å®Œç¾çš„é¡Œç›®ç”Ÿæˆæ ¼å¼å®Œç¾çš„ç­”æ¡ˆ
                    answer_data = await self.gemini.generate_answer(question_text)
                    answer_text = format_answer_text(self._extract_answer_string(answer_data)) # format_answer_text æ˜¯å®‰å…¨çš„
                    sources_json = json.dumps(answer_data.get('sources', []), ensure_ascii=False)
                    
                    # æ­¥é©Ÿ 3: å°‡å®Œç¾æ ¼å¼çš„é¡Œç›®å’Œç­”æ¡ˆç›´æ¥å­˜å…¥è³‡æ–™åº«ï¼Œç§»é™¤æ‰€æœ‰ format_code_blocks()
                    question_id = self.db.insert_question(
                        document_id=doc_id,
                        title=question_data.get('title', f'é¡Œç›® {i}'),
                        question_text=question_text,        # <--- å·²ä¿®æ­£
                        answer_text=answer_text,            # <--- å·²ä¿®æ­£
                        answer_sources=sources_json,
                        subject=subject,
                        difficulty=question_data.get('difficulty'),
                        guidance_level=question_data.get('guidance_level')
                    )
                    
                    await self.mindmap_flow.generate_and_save_mindmap(question_id)
                    
                    knowledge_points = question_data.get('knowledge_points', [])
                    for kp_name in knowledge_points:
                        kp_id = self.db.add_or_get_knowledge_point(kp_name.strip(), subject)
                        self.db.link_question_to_knowledge_point(question_id, kp_id)
                        all_knowledge_points.add(kp_name.strip())
                    
                    saved_questions.append({
                        'id': question_id,
                        'stem': question_text,
                        'answer': answer_text,
                        'sources': answer_data.get('sources', []),
                        'knowledge_points': knowledge_points
                    })
                except Exception as e:
                    print(f"    è™•ç†ç¬¬ {i} é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                    continue
            
            return {
                'success': True,
                'content_type': 'exam_paper',
                'subject': subject,
                'document_id': doc_id,
                'questions': saved_questions,
                'knowledge_points': list(all_knowledge_points),
                'message': f'æˆåŠŸè™•ç†è€ƒé¡Œï¼Œè§£æäº† {len(saved_questions)} é“é¡Œç›®ã€‚'
            }

    async def _process_study_material(self, content: str, subject: str, doc_id: int, parsed_data: Dict) -> Dict[str, Any]:
        """å­¸ç¿’è³‡æ–™è™•ç†æµç¨‹"""
        print("ğŸ“š åŸ·è¡Œå­¸ç¿’è³‡æ–™è™•ç†æµç¨‹...")
        
        # æ­¥é©Ÿ 1: AI ç”Ÿæˆä¸€çµ„åŒ…å«é¡Œç›®å’Œç­”æ¡ˆçš„æ¨¡æ“¬é¡Œ
        generated_questions = await self.gemini.generate_questions_from_text(content, subject)
        saved_questions = []
        all_knowledge_points = set()

        for q_data in generated_questions:
            # æ­¥é©Ÿ 2: ä½¿ç”¨ sanitize æ¸…ç†é¡Œç›®æ–‡å­—
            q_text = self._sanitize_question_text(q_data.get('question', ''))

            # å°æ–¼æ¨¡æ“¬é¡Œï¼Œæˆ‘å€‘ä½¿ç”¨ generate_answer é‡æ–°ç”Ÿæˆç­”æ¡ˆï¼Œç¢ºä¿ç­”æ¡ˆå“è³ª
            answer_data = await self.gemini.generate_answer(q_text)
            answer_text = format_answer_text(self._extract_answer_string(answer_data))
            sources_json = json.dumps(answer_data.get('sources', []), ensure_ascii=False)

            # æ­¥é©Ÿ 3: å°‡å®Œç¾æ ¼å¼çš„å…§å®¹ç›´æ¥å­˜å…¥è³‡æ–™åº«
            question_id = self.db.insert_question(
                document_id=doc_id,
                title=q_data.get('title', 'æ¨¡æ“¬é¡Œ'),
                question_text=q_text,               # <--- å·²ä¿®æ­£
                answer_text=answer_text,            # <--- å·²ä¿®æ­£
                answer_sources=sources_json,
                subject=subject,
                difficulty=q_data.get('difficulty'),
            )
            
            # æ­¥é©Ÿ 4: è™•ç†çŸ¥è­˜é»é—œè¯ (æ–°å¢)
            knowledge_points = q_data.get('knowledge_points', [])
            if knowledge_points:
                print(f"ğŸ”— ç‚ºé¡Œç›® {question_id} é—œè¯çŸ¥è­˜é»: {knowledge_points}")
                for kp_name in knowledge_points:
                    # æ–°å¢æˆ–å–å¾—çŸ¥è­˜é»
                    kp_id = self.db.add_or_get_knowledge_point(
                        name=kp_name.strip(),
                        subject=subject,
                        description=f"ä¾†è‡ªå­¸ç¿’è³‡æ–™ï¼š{parsed_data.get('title', 'æœªçŸ¥æ–‡ä»¶')}"
                    )
                    # é—œè¯é¡Œç›®èˆ‡çŸ¥è­˜é»
                    self.db.link_question_to_knowledge_point(question_id, kp_id)
                    all_knowledge_points.add(kp_name.strip())
            else:
                print(f"âš ï¸ é¡Œç›® {question_id} æ²’æœ‰ç”ŸæˆçŸ¥è­˜é»")
            
            # ç”Ÿæˆå¿ƒæ™ºåœ–
            mindmap_result = await self.mindmap_flow.generate_and_save_mindmap(question_id)
            
            # å°‡å¿ƒæ™ºåœ–ç¨‹å¼ç¢¼å„²å­˜åˆ° mindmap_code æ¬„ä½
            if mindmap_result and mindmap_result.get('success'):
                self.db.update_question_mindmap(question_id, mindmap_result.get('mindmap_code', ''))
            
            # ç”Ÿæˆè§£é¡ŒæŠ€å·§ (æ–°å¢)
            try:
                print(f"ğŸ§  ç‚ºé¡Œç›® {question_id} ç”Ÿæˆè§£é¡ŒæŠ€å·§...")
                summary_result = await self.gemini.generate_question_summary(q_text, q_data.get('title', ''))
                if summary_result and 'summary' in summary_result and 'solving_tips' in summary_result:
                    self.db.update_question_solving_tips(
                        question_id,
                        summary_result['summary'],
                        summary_result['solving_tips']
                    )
                    print(f"âœ… è§£é¡ŒæŠ€å·§å·²ç”Ÿæˆä¸¦å„²å­˜")
                else:
                    print(f"âš ï¸ è§£é¡ŒæŠ€å·§ç”Ÿæˆå¤±æ•—")
            except Exception as e:
                print(f"âŒ ç”Ÿæˆè§£é¡ŒæŠ€å·§æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

            q_data['id'] = question_id
            q_data['question'] = q_text
            q_data['answer'] = answer_text
            saved_questions.append(q_data)

        # ç”Ÿæˆæ‘˜è¦å’Œæ¸¬é©—
        summary_raw_data = await self.gemini.generate_summary(content)
        # ç¢ºä¿ summary_data æ˜¯å­—å…¸ï¼Œå¦‚æœä¸æ˜¯å‰‡å˜—è©¦è§£æ
        if isinstance(summary_raw_data, str):
            try:
                summary_data = json.loads(summary_raw_data)
            except json.JSONDecodeError:
                summary_data = {} # è§£æå¤±æ•—å‰‡è¨­ç‚ºç©ºå­—å…¸
        else:
            summary_data = summary_raw_data

        quiz_data = await self.gemini.generate_quick_quiz(content, subject)

        # å„²å­˜æ‘˜è¦å’Œæ¸¬é©—
        summary_text = format_summary_to_markdown(summary_data) if summary_data else None
        quiz_text = json.dumps(quiz_data, ensure_ascii=False) if quiz_data else None
        self.db.update_document_summary_and_quiz(doc_id, summary_text, quiz_text)

        return {
            'success': True,
            'content_type': 'study_material',
            'subject': subject,
            'document_id': doc_id,
            'questions': saved_questions,
            'knowledge_points': list(all_knowledge_points),
            'summary': summary_data,
            'quiz': quiz_data,
            'message': f'å­¸ç¿’è³‡æ–™è™•ç†å®Œæˆï¼ç”Ÿæˆäº† {len(saved_questions)} é“æ¨¡æ“¬é¡Œã€‚'
        }