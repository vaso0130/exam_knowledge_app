from typing import Dict, Any
import asyncio
import concurrent.futures
from src.core.gemini_client import GeminiClient
from src.core.database import DatabaseManager
import json
from ..utils.markdown_utils import (
    format_code_blocks,
    format_summary_to_markdown,
    format_answer_text,
    detect_and_fence_indented_code,
)
from ..flows.mindmap_flow import MindmapFlow

class ContentFlow:
    """å…§å®¹è™•ç†æµç¨‹ç®¡ç†å™¨ - çµ±ä¸€ç®¡ç†æ‰€æœ‰å…§å®¹åˆ†æã€å•é¡Œç”Ÿæˆå’ŒçŸ¥è­˜é»é—œè¯"""
    
    def __init__(self, gemini_client: GeminiClient, db_manager: DatabaseManager):
        self.gemini = gemini_client
        self.db = db_manager
        from ..utils.file_processor import FileProcessor
        self.file_processor = FileProcessor()
        self.mindmap_flow = MindmapFlow(gemini_client, db_manager)

    @staticmethod
    def _sanitize_question_text(text: str) -> str:
        """ç§»é™¤å¯èƒ½åŒ…å«è§£ç­”æˆ–èªªæ˜æ¨™é¡Œçš„è¡Œï¼Œä½†ä¿ç•™ç¨‹å¼ç¢¼å€å¡Šå…§çš„å…§å®¹"""
        if not text:
            return text
        import re
        pattern = re.compile(r"^\s*(ç­”æ¡ˆ|è§£ç­”|åƒè€ƒç­”æ¡ˆ|å»ºè­°|èªªæ˜|è§£æ)[\s:ï¼š]", re.I)
        lines = text.splitlines()
        sanitized_lines = []
        in_code_block = False

        for line in lines:
            if line.strip().startswith("```"):
                in_code_block = not in_code_block
                sanitized_lines.append(line)
            elif in_code_block:
                sanitized_lines.append(line)
            elif not pattern.match(line):
                sanitized_lines.append(line)

        cleaned = "\n".join(sanitized_lines).strip()
        return detect_and_fence_indented_code(cleaned)

    async def _process_single_question_concurrently(self, question_data: Dict, doc_id: int, subject: str, question_index: int, is_generated_question: bool = False) -> Dict:
        """
        [æ–°å‡½å¼] ä¸¦è¡Œè™•ç†å–®ä¸€å•é¡Œçš„æ ¸å¿ƒé‚è¼¯ã€‚
        é€™å€‹å‡½å¼æœƒè¢« asyncio.gather å‘¼å«ã€‚
        
        Args:
            question_data: å•é¡Œè³‡æ–™
            doc_id: æ–‡ä»¶ID
            subject: ç§‘ç›®
            question_index: å•é¡Œç´¢å¼•
            is_generated_question: æ˜¯å¦ç‚ºç”Ÿæˆçš„æ¨¡æ“¬é¡Œ
        """
        try:
            # å¾å‚³å…¥çš„è³‡æ–™ç²å–é¡Œå¹¹
            if is_generated_question:
                # å°æ–¼æ¨¡æ“¬é¡Œï¼Œä½¿ç”¨ question æ¬„ä½
                question_text = self._sanitize_question_text(question_data.get('question', ''))
            else:
                # å°æ–¼è€ƒé¡Œï¼Œä½¿ç”¨ stem æ¬„ä½
                question_text = question_data.get('stem') or question_data.get('question')
            
            if not question_text:
                return {'success': False, 'error': 'é¡Œå¹¹ç‚ºç©º'}

            print(f"    ğŸ”„ é–‹å§‹ä¸¦è¡Œè™•ç†ç¬¬ {question_index} é¡Œ...")

            # 1. ç”Ÿæˆç­”æ¡ˆ (I/O å¯†é›†å‹)
            answer_data = await self.gemini.generate_answer(question_text)
            answer_text = format_answer_text(self._extract_answer_string(answer_data))
            sources_json = json.dumps(answer_data.get('sources', []), ensure_ascii=False)

            # 2. å­˜å…¥è³‡æ–™åº« (I/O å¯†é›†å‹)
            question_id = self.db.insert_question(
                document_id=doc_id,
                title=question_data.get('title', f'é¡Œç›® {question_index}'),
                question_text=question_text,
                answer_text=answer_text,
                answer_sources=sources_json,
                subject=subject,
                difficulty=question_data.get('difficulty'),
                guidance_level=question_data.get('guidance_level')
            )

            # 3. è™•ç†çŸ¥è­˜é» (CPU/I/O æ··åˆ)
            knowledge_points = question_data.get('knowledge_points', [])
            if knowledge_points:
                print(f"    ğŸ”— ç‚ºé¡Œç›® {question_id} é—œè¯ {len(knowledge_points)} å€‹çŸ¥è­˜é»")
                for kp_name in knowledge_points:
                    kp_id = self.db.add_or_get_knowledge_point(
                        name=kp_name.strip(),
                        subject=subject,
                        description=f"ä¾†è‡ª{'æ¨¡æ“¬é¡Œ' if is_generated_question else 'è€ƒé¡Œ'}ç”Ÿæˆ"
                    )
                    self.db.link_question_to_knowledge_point(question_id, kp_id)

            # 4. ç”Ÿæˆå¿ƒæ™ºåœ– (I/O å¯†é›†å‹)
            mindmap_result = await self.mindmap_flow.generate_and_save_mindmap(question_id)
            if mindmap_result and mindmap_result.get('success'):
                self.db.update_question_mindmap(question_id, mindmap_result.get('mindmap_code', ''))

            # 5. ç”Ÿæˆè§£é¡ŒæŠ€å·§ (åƒ…é™æ¨¡æ“¬é¡Œï¼ŒI/O å¯†é›†å‹)
            if is_generated_question:
                try:
                    summary_result = await self.gemini.generate_question_summary(question_text, question_data.get('title', ''))
                    if summary_result and 'summary' in summary_result and 'solving_tips' in summary_result:
                        self.db.update_question_solving_tips(
                            question_id,
                            summary_result['summary'],
                            summary_result['solving_tips']
                        )
                        print(f"    âœ… é¡Œç›® {question_id} è§£é¡ŒæŠ€å·§å·²ç”Ÿæˆ")
                except Exception as e:
                    print(f"    âš ï¸ é¡Œç›® {question_id} è§£é¡ŒæŠ€å·§ç”Ÿæˆå¤±æ•—: {e}")

            print(f"    âœ… ç¬¬ {question_index} é¡Œè™•ç†å®Œæˆ (ID: {question_id})")

            # 6. å›å‚³çµæ§‹åŒ–è™•ç†çµæœ
            return {
                'success': True,
                'id': question_id,
                'stem': question_text,
                'answer': answer_text,
                'sources': answer_data.get('sources', []),
                'knowledge_points': knowledge_points
            }
        except Exception as e:
            print(f"    âŒ è™•ç†ç¬¬ {question_index} é¡Œæ™‚ä¸¦è¡Œç™¼ç”ŸéŒ¯èª¤: {e}")
            return {'success': False, 'error': str(e), 'stem': question_data.get('stem', 'N/A')}

    
    
    def process_file(self, file_path: str, filename: str, suggested_subject: str = None) -> Dict[str, Any]:
        """è™•ç†æª”æ¡ˆçš„çµ±ä¸€å…¥å£é»"""
        try:
            # content is the extracted text from the file
            content, _ = self.file_processor.process_input(file_path)

            # Pass the file_path along with the extracted content
            return self.complete_ai_processing(content, filename, suggested_subject, file_path=file_path)
        except Exception as e:
            print(f"è™•ç†æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return {'success': False, 'error': str(e), 'message': f'æª”æ¡ˆè™•ç†å¤±æ•—: {str(e)}'}
    
    def complete_ai_processing(self, content: str, filename: str, suggested_subject: str = None, source_url: str = None, file_path: str = None) -> Dict[str, Any]:
        """å®Œæ•´ AI è™•ç†æµç¨‹"""
        try:
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(asyncio.run, self._run_async_processing(content, filename, suggested_subject, source_url, file_path))
                return future.result()
        except Exception as e:
            print(f"å®Œæ•´ AI è™•ç†æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return {'success': False, 'error': str(e), 'message': 'è™•ç†å¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦'}
    
    def _extract_answer_string(self, answer_data: Any) -> str:
        """Recursively extracts the answer string from potentially nested answer_data."""
        if isinstance(answer_data, dict):
            if 'answer' in answer_data:
                extracted_answer = self._extract_answer_string(answer_data['answer'])
                if not extracted_answer or "not included in the prompt" in extracted_answer.lower() or "answer is not provided" in extracted_answer.lower():
                    return "ï¼ˆåƒè€ƒç­”æ¡ˆç”Ÿæˆå¤±æ•—æˆ–æœªæä¾›ï¼Œè«‹æª¢æŸ¥åŸå§‹è³‡æ–™æˆ–ç¨å¾Œé‡è©¦ã€‚ï¼‰"
                return extracted_answer
            else:
                return json.dumps(answer_data, ensure_ascii=False)
        elif isinstance(answer_data, list):
            return json.dumps(answer_data, ensure_ascii=False)
        else:
            extracted_answer = str(answer_data)
            if not extracted_answer or "not included in the prompt" in extracted_answer.lower() or "answer is not provided" in extracted_answer.lower():
                return "ï¼ˆåƒè€ƒç­”æ¡ˆç”Ÿæˆå¤±æ•—æˆ–æœªæä¾›ï¼Œè«‹æª¢æŸ¥åŸå§‹è³‡æ–™æˆ–ç¨å¾Œé‡è©¦ã€‚ï¼‰"
            return extracted_answer

    async def _run_async_processing(self, content: str, filename: str, suggested_subject: str = None, source_url: str = None, file_path: str = None) -> Dict[str, Any]:
        """åŸ·è¡Œç•°æ­¥è™•ç†æµç¨‹"""
        try:
            print("ğŸ¤– AI æ­£åœ¨åˆ†æå…§å®¹é¡å‹...")
            parsed_data = await self.gemini.parse_exam_paper(content)

            # # ======================================================================
            # # â–¼â–¼â–¼ DEBUG CHECKPOINT 2 (å·²ä¿®æ­£) â–¼â–¼â–¼
            # print("\n" + "="*20 + " DEBUG CHECKPOINT 2: AFTER parse_exam_paper " + "="*20)
            # print("--- Full parsed_data from AI ---")
            # print(json.dumps(parsed_data, indent=2, ensure_ascii=False))
            # # ä¿®æ­£ï¼šè¿­ä»£ questions åˆ—è¡¨ä¾†å°å‡ºæ¯å€‹ stem
            # if parsed_data.get('questions'):
            #     for i, q_data in enumerate(parsed_data['questions']):
            #         stem_text = q_data.get('stem', 'STEM NOT FOUND')
            #         print(f"\n--- Extracted 'stem' from Question {i+1} ---")
            #         print(stem_text)
            # print("="*70 + "\n")
            # # â–²â–²â–² DEBUG CHECKPOINT 2 (å·²ä¿®æ­£) â–²â–²â–²
            # # ======================================================================
            
            content_type = parsed_data.get('content_type', 'study_material')
            detected_subject = parsed_data.get('subject', suggested_subject or 'å…¶ä»–')
            
            print(f"ğŸ“‹ å…§å®¹åˆ†é¡çµæœï¼š{content_type} ({detected_subject})")
            
            doc_id = self.db.add_document(
                title=filename, 
                content=content, # Extracted text
                subject=detected_subject, 
                source=source_url,
                file_path=file_path # The actual file path
            )
            
            if content_type == 'exam_paper':
                print("ğŸ“ æª¢æ¸¬åˆ°è€ƒé¡Œå…§å®¹ï¼ŒåŸ·è¡Œè€ƒé¡Œè™•ç†æµç¨‹...")
                result = await self._process_exam_content(content, detected_subject, doc_id, parsed_data)
            else:
                print("ğŸ“š æª¢æ¸¬åˆ°å­¸ç¿’è³‡æ–™ï¼ŒåŸ·è¡Œå­¸ç¿’è³‡æ–™è™•ç†æµç¨‹...")
                result = await self._process_study_material(content, detected_subject, doc_id, parsed_data)
            
            if result.get('success'):
                return result
            else:
                return result
                
        except Exception as e:
            print(f"ç•°æ­¥è™•ç†æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise e
    
    async def _process_exam_content(self, content: str, subject: str, doc_id: int, parsed_data: Dict) -> Dict[str, Any]:
        """è€ƒé¡Œè™•ç†æµç¨‹ (å·²å‡ç´šç‚ºä¸¦è¡Œè™•ç†)"""
        questions_from_ai = parsed_data.get('questions', [])
        print(f"ğŸ“ æª¢æ¸¬åˆ° {len(questions_from_ai)} é“è€ƒé¡Œï¼Œé–‹å§‹ä¸¦è¡Œè™•ç†...")

        # 1. å»ºç«‹æ‰€æœ‰å•é¡Œçš„è™•ç†ä»»å‹™åˆ—è¡¨
        tasks = []
        for i, question_data in enumerate(questions_from_ai, 1):
            task = self._process_single_question_concurrently(
                question_data=question_data,
                doc_id=doc_id,
                subject=subject,
                question_index=i,
                is_generated_question=False  # é€™æ˜¯è€ƒé¡Œï¼Œä¸æ˜¯æ¨¡æ“¬é¡Œ
            )
            tasks.append(task)

        # 2. ä½¿ç”¨ asyncio.gather ä¸€æ¬¡æ€§åŸ·è¡Œæ‰€æœ‰ä»»å‹™
        print(f"ğŸš€ é–‹å§‹ä¸¦è¡Œè™•ç† {len(tasks)} å€‹è€ƒé¡Œä»»å‹™...")
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # 3. æ”¶é›†è™•ç†çµæœ
        saved_questions = []
        all_knowledge_points = set()
        failed_count = 0
        
        for result in results:
            if isinstance(result, Exception):
                print(f"ä¸€å€‹ä»»å‹™åŸ·è¡Œæ™‚ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {result}")
                failed_count += 1
            elif result.get('success'):
                saved_questions.append(result)
                for kp in result.get('knowledge_points', []):
                    all_knowledge_points.add(kp.strip())
            else:
                print(f"ä¸€å€‹ä»»å‹™è™•ç†å¤±æ•—: {result.get('error')}")
                failed_count += 1

        message = f'æˆåŠŸè™•ç†è€ƒé¡Œï¼Œå…± {len(saved_questions)} é“æˆåŠŸï¼Œ{failed_count} é“å¤±æ•—ã€‚'
        print(f"ğŸ“Š {message}")
        
        return {
            'success': True,
            'content_type': 'exam_paper',
            'subject': subject,
            'document_id': doc_id,
            'questions': saved_questions,
            'knowledge_points': list(all_knowledge_points),
            'message': message
        }

    async def _process_study_material(self, content: str, subject: str, doc_id: int, parsed_data: Dict) -> Dict[str, Any]:
        """å­¸ç¿’è³‡æ–™è™•ç†æµç¨‹ (æ¨¡æ“¬é¡Œéƒ¨åˆ†å·²å‡ç´šç‚ºä¸¦è¡Œè™•ç†)"""
        print("ğŸ“š åŸ·è¡Œå­¸ç¿’è³‡æ–™è™•ç†æµç¨‹...")
        
        # æ­¥é©Ÿ 1: AI ç”Ÿæˆä¸€çµ„åŒ…å«é¡Œç›®å’Œç­”æ¡ˆçš„æ¨¡æ“¬é¡Œ
        generated_questions = await self.gemini.generate_questions_from_text(content, subject)
        print(f"ğŸ¤– AI å·²ç”Ÿæˆ {len(generated_questions)} é“æ¨¡æ“¬é¡Œï¼Œé–‹å§‹ä¸¦è¡Œè™•ç†...")

        # 2. å»ºç«‹æ‰€æœ‰æ¨¡æ“¬é¡Œçš„è™•ç†ä»»å‹™åˆ—è¡¨
        tasks = []
        for i, q_data in enumerate(generated_questions, 1):
            task = self._process_single_question_concurrently(
                question_data=q_data,
                doc_id=doc_id,
                subject=subject,
                question_index=i,
                is_generated_question=True  # é€™æ˜¯æ¨¡æ“¬é¡Œ
            )
            tasks.append(task)

        # 3. ä½¿ç”¨ asyncio.gather ä¸€æ¬¡æ€§åŸ·è¡Œæ‰€æœ‰ä»»å‹™
        print(f"ï¿½ é–‹å§‹ä¸¦è¡Œè™•ç† {len(tasks)} å€‹æ¨¡æ“¬é¡Œä»»å‹™...")
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # 4. æ”¶é›†è™•ç†çµæœ
        saved_questions = []
        all_knowledge_points = set()
        failed_count = 0

        for result in results:
            if isinstance(result, Exception):
                print(f"ä¸€å€‹æ¨¡æ“¬é¡Œä»»å‹™åŸ·è¡Œæ™‚ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {result}")
                failed_count += 1
            elif result.get('success'):
                # è½‰æ›æ ¼å¼ä»¥ç¬¦åˆåŸä¾†çš„æœŸæœ›
                saved_questions.append({
                    'id': result['id'],
                    'question': result['stem'],
                    'answer': result['answer'],
                    'knowledge_points': result['knowledge_points']
                })
                for kp in result.get('knowledge_points', []):
                    all_knowledge_points.add(kp.strip())
            else:
                print(f"ä¸€å€‹æ¨¡æ“¬é¡Œä»»å‹™è™•ç†å¤±æ•—: {result.get('error')}")
                failed_count += 1
        
        print(f"ğŸ“Š æ¨¡æ“¬é¡Œä¸¦è¡Œè™•ç†å®Œæˆï¼š{len(saved_questions)} é“æˆåŠŸï¼Œ{failed_count} é“å¤±æ•—")

        # 5. å¾ŒçºŒçš„æ‘˜è¦å’Œæ¸¬é©—è™•ç†ä¿æŒä¸è®Šï¼Œå› ç‚ºé€™äº›ä¸æ˜¯é‡è¤‡æ€§ä»»å‹™
        print("ğŸ“„ é–‹å§‹ç”Ÿæˆæ‘˜è¦...")
        summary_raw_data = await self.gemini.generate_summary(content)
        # ç¢ºä¿ summary_data æ˜¯å­—å…¸ï¼Œå¦‚æœä¸æ˜¯å‰‡å˜—è©¦è§£æ
        if isinstance(summary_raw_data, str):
            try:
                summary_data = json.loads(summary_raw_data)
            except json.JSONDecodeError:
                summary_data = {} # è§£æå¤±æ•—å‰‡è¨­ç‚ºç©ºå­—å…¸
        else:
            summary_data = summary_raw_data

        print("ğŸ§© é–‹å§‹ç”Ÿæˆå¿«é€Ÿæ¸¬é©—...")
        quiz_data = await self.gemini.generate_quick_quiz(content, subject)

        # å„²å­˜æ‘˜è¦å’Œæ¸¬é©—
        summary_text = format_summary_to_markdown(summary_data) if summary_data else None
        quiz_text = json.dumps(quiz_data, ensure_ascii=False) if quiz_data else None
        self.db.update_document_summary_and_quiz(doc_id, summary_text, quiz_text)

        message = f'å­¸ç¿’è³‡æ–™è™•ç†å®Œæˆï¼ç”Ÿæˆäº† {len(saved_questions)} é“æ¨¡æ“¬é¡Œ ({failed_count} é“å¤±æ•—)ã€‚'
        print(f"ğŸ‰ {message}")

        return {
            'success': True,
            'content_type': 'study_material',
            'subject': subject,
            'document_id': doc_id,
            'questions': saved_questions,
            'knowledge_points': list(all_knowledge_points),
            'summary': summary_data,
            'quiz': quiz_data,
            'message': message
        }