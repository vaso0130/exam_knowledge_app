åŠŸèƒ½è«‹æ±‚ï¼šå°‡å¾ªåºé¡Œç›®è™•ç†å‡ç´šç‚ºä¸¦è¡Œè™•ç†

ç›®æ¨™ï¼š ç‚ºäº†å¤§å¹…æå‡ç³»çµ±è™•ç†å¤šå€‹é¡Œç›®æ™‚çš„æ•ˆèƒ½ï¼Œéœ€è¦å°‡ src/flows/content_flow.py ä¸­è™•ç†é¡Œç›®çš„å¾ªåº for è¿´åœˆï¼Œé‡æ§‹ç‚ºä½¿ç”¨ asyncio.gather çš„ä¸¦è¡Œï¼ˆConcurrentï¼‰æ¨¡å¼ã€‚

1. æ ¸å¿ƒæ¦‚å¿µ

ç›®å‰çš„è™•ç†æµç¨‹æ˜¯ã€ŒåŒæ­¥é˜»å¡ã€çš„ï¼š

èˆŠæ¨¡å¼ï¼šfor é¡Œç›® in é¡Œç›®åˆ—è¡¨: await è™•ç†(é¡Œç›®)

ç¼ºé»ï¼šè™•ç†ä¸€é¡Œæ™‚ï¼ŒCPU å¤§éƒ¨åˆ†æ™‚é–“éƒ½åœ¨ç­‰å¾…ç¶²è·¯ I/Oï¼ˆå‘¼å« Gemini APIï¼‰ã€‚å¦‚æœä¸€ä»½æ–‡ä»¶æœ‰ 5 é“é¡Œï¼Œæ¯é¡Œè™•ç†è€—æ™‚ 10 ç§’ï¼Œç¸½è€—æ™‚ç´„ç‚º 50 ç§’ã€‚

éœ€è¦é‡æ§‹ç‚ºã€Œä¸¦è¡Œã€æ¨¡å¼ï¼š

æ–°æ¨¡å¼ï¼šawait asyncio.gather(è™•ç†(é¡Œç›®1), è™•ç†(é¡Œç›®2), ...)

å„ªé»ï¼šä¸€æ¬¡æ€§ç™¼å‡ºæ‰€æœ‰ API è«‹æ±‚ï¼Œä¸¦è¡Œç­‰å¾…æ‰€æœ‰å›æ‡‰ã€‚ç¸½è€—æ™‚ç´„ç­‰æ–¼è™•ç†æœ€æ…¢é‚£ä¸€é¡Œçš„æ™‚é–“ã€‚ä¸Šè¿°ä¾‹å­ä¸­ï¼Œç¸½è€—æ™‚å¯èƒ½ç¸®çŸ­è‡³ 10-15 ç§’ã€‚

2. é‡æ§‹æ­¥é©Ÿ
æ­¥é©Ÿ 2.1ï¼šå‰µå»ºä¸€å€‹å¯é‡ç”¨çš„ä¸¦è¡Œè™•ç†è¼”åŠ©å‡½å¼

åœ¨ src/flows/content_flow.py çš„ ContentFlow class å…§éƒ¨ï¼Œæ–°å¢ä¸€å€‹ async è¼”åŠ©å‡½å¼ï¼Œç”¨æ–¼å°è£è™•ç†å–®ä¸€å•é¡Œçš„æ‰€æœ‰é‚è¼¯ã€‚é€™å€‹å‡½å¼å°‡è¢« asyncio.gather å¤šæ¬¡å‘¼å«ã€‚

æ–°å¢å‡½å¼ _process_single_question_concurrentlyï¼š

Generated python
# ä½ç½®: src/flows/content_flow.py (class ContentFlow å…§éƒ¨)

    async def _process_single_question_concurrently(self, question_data: Dict, doc_id: int, subject: str, question_index: int) -> Dict:
        """
        [æ–°å‡½å¼] ä¸¦è¡Œè™•ç†å–®ä¸€å•é¡Œçš„æ ¸å¿ƒé‚è¼¯ã€‚
        é€™å€‹å‡½å¼æœƒè¢« asyncio.gather å‘¼å«ã€‚
        """
        try:
            # å¾å‚³å…¥çš„è³‡æ–™ç²å–é¡Œå¹¹
            question_text = question_data.get('stem') or question_data.get('question')
            if not question_text:
                return {'success': False, 'error': 'é¡Œå¹¹ç‚ºç©º'}

            # 1. ç”Ÿæˆç­”æ¡ˆ (I/O å¯†é›†å‹)
            answer_data = await self.gemini.generate_answer(question_text)
            answer_text = format_answer_text(self._extract_answer_string(answer_data))
            sources_json = json.dumps(answer_data.get('sources', []), ensure_ascii=False)

            # 2. å­˜å…¥è³‡æ–™åº« (I/O å¯†é›†å‹)
            question_id = self.db.insert_question(
                document_id=doc_id,
                title=question_data.get('title', f'é¡Œç›® {question_index}'),
                question_text=question_text,
                answer_text=answer_text,
                answer_sources=sources_json,
                subject=subject,
                difficulty=question_data.get('difficulty'),
                guidance_level=question_data.get('guidance_level')
            )

            # 3. ç”Ÿæˆå¿ƒæ™ºåœ– (I/O å¯†é›†å‹)
            await self.mindmap_flow.generate_and_save_mindmap(question_id)

            # 4. è™•ç†çŸ¥è­˜é» (CPU/I/O æ··åˆ)
            knowledge_points = question_data.get('knowledge_points', [])
            for kp_name in knowledge_points:
                kp_id = self.db.add_or_get_knowledge_point(kp_name.strip(), subject)
                self.db.link_question_to_knowledge_point(question_id, kp_id)

            # 5. å›å‚³çµæ§‹åŒ–è™•ç†çµæœ
            return {
                'success': True,
                'id': question_id,
                'stem': question_text,
                'answer': answer_text,
                'sources': answer_data.get('sources', []),
                'knowledge_points': knowledge_points
            }
        except Exception as e:
            print(f"    è™•ç†ç¬¬ {question_index} é¡Œæ™‚ä¸¦è¡Œç™¼ç”ŸéŒ¯èª¤: {e}")
            return {'success': False, 'error': str(e), 'stem': question_data.get('stem', 'N/A')}

æ­¥é©Ÿ 2.2ï¼šé‡æ§‹ _process_exam_content å‡½å¼

ä¿®æ”¹æ­¤å‡½å¼ï¼Œç”¨æ–°çš„ä¸¦è¡Œæ¨¡å¼å–ä»£èˆŠçš„ for è¿´åœˆã€‚

ä¿®æ”¹å‰ _process_exam_contentï¼š

Generated python
# src/flows/content_flow.py

    async def _process_exam_content(self, content: str, subject: str, doc_id: int, parsed_data: Dict) -> Dict[str, Any]:
        """è€ƒé¡Œè™•ç†æµç¨‹"""
        questions = parsed_data.get('questions', [])
        saved_questions = []
        all_knowledge_points = set()
        
        print(f"ğŸ“ é–‹å§‹è™•ç† {len(questions)} é“è€ƒé¡Œ...")
        
        for i, question_data in enumerate(questions, 1):
            try:
                # ... (æ­¤è™•ç‚ºå¾ªåºè™•ç†é‚è¼¯) ...
            except Exception as e:
                print(f"    è™•ç†ç¬¬ {i} é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                continue
        # ... (å¾ŒçºŒè™•ç†) ...
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Python
IGNORE_WHEN_COPYING_END

ä¿®æ”¹å¾Œ _process_exam_contentï¼š

Generated python
# src/flows/content_flow.py

    async def _process_exam_content(self, content: str, subject: str, doc_id: int, parsed_data: Dict) -> Dict[str, Any]:
        """è€ƒé¡Œè™•ç†æµç¨‹ (å·²å‡ç´šç‚ºä¸¦è¡Œè™•ç†)"""
        questions_from_ai = parsed_data.get('questions', [])
        print(f"ğŸ“ æª¢æ¸¬åˆ° {len(questions_from_ai)} é“è€ƒé¡Œï¼Œé–‹å§‹ä¸¦è¡Œè™•ç†...")

        # 1. å»ºç«‹æ‰€æœ‰å•é¡Œçš„è™•ç†ä»»å‹™åˆ—è¡¨
        tasks = []
        for i, question_data in enumerate(questions_from_ai, 1):
            task = self._process_single_question_concurrently(
                question_data=question_data,
                doc_id=doc_id,
                subject=subject,
                question_index=i
            )
            tasks.append(task)

        # 2. ä½¿ç”¨ asyncio.gather ä¸€æ¬¡æ€§åŸ·è¡Œæ‰€æœ‰ä»»å‹™
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # 3. æ”¶é›†è™•ç†çµæœ
        saved_questions = []
        all_knowledge_points = set()
        failed_count = 0
        
        for result in results:
            if isinstance(result, Exception):
                print(f"ä¸€å€‹ä»»å‹™åŸ·è¡Œæ™‚ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {result}")
                failed_count += 1
            elif result.get('success'):
                saved_questions.append(result)
                for kp in result.get('knowledge_points', []):
                    all_knowledge_points.add(kp.strip())
            else:
                print(f"ä¸€å€‹ä»»å‹™è™•ç†å¤±æ•—: {result.get('error')}")
                failed_count += 1

        message = f'æˆåŠŸè™•ç†è€ƒé¡Œï¼Œå…± {len(saved_questions)} é“æˆåŠŸï¼Œ{failed_count} é“å¤±æ•—ã€‚'
        print(message)
        
        return {
            'success': True,
            'content_type': 'exam_paper',
            'subject': subject,
            'document_id': doc_id,
            'questions': saved_questions,
            'knowledge_points': list(all_knowledge_points),
            'message': message
        }```

#### æ­¥é©Ÿ 2.3ï¼šé‡æ§‹ `_process_study_material` å‡½å¼

å°æ­¤å‡½å¼ä¸­ç”Ÿæˆã€Œæ¨¡æ“¬é¡Œã€çš„éƒ¨åˆ†ï¼Œä¹Ÿæ‡‰ç”¨åŒæ¨£çš„ä¸¦è¡Œè™•ç†æ¨¡å¼ã€‚

**ä¿®æ”¹å‰ `_process_study_material` (éƒ¨åˆ†)ï¼š**
```python
# src/flows/content_flow.py

    async def _process_study_material(self, content: str, subject: str, doc_id: int, parsed_data: Dict) -> Dict[str, Any]:
        # ...
        generated_questions = await self.gemini.generate_questions_from_text(content, subject)
        saved_questions = []
        all_knowledge_points = set()

        for q_data in generated_questions:
            # ... (æ­¤è™•ç‚ºå¾ªåºè™•ç†é‚è¼¯) ...
        # ... (å¾ŒçºŒè™•ç†) ...```

**ä¿®æ”¹å¾Œ `_process_study_material` (éƒ¨åˆ†)ï¼š**
```python
# src/flows/content_flow.py

    async def _process_study_material(self, content: str, subject: str, doc_id: int, parsed_data: Dict) -> Dict[str, Any]:
        """å­¸ç¿’è³‡æ–™è™•ç†æµç¨‹ (æ¨¡æ“¬é¡Œéƒ¨åˆ†å·²å‡ç´šç‚ºä¸¦è¡Œè™•ç†)"""
        print("ğŸ“š åŸ·è¡Œå­¸ç¿’è³‡æ–™è™•ç†æµç¨‹...")
        
        generated_questions = await self.gemini.generate_questions_from_text(content, subject)
        print(f"ğŸ¤– AI å·²ç”Ÿæˆ {len(generated_questions)} é“æ¨¡æ“¬é¡Œï¼Œé–‹å§‹ä¸¦è¡Œè™•ç†...")

        # 1. å»ºç«‹æ‰€æœ‰æ¨¡æ“¬é¡Œçš„è™•ç†ä»»å‹™åˆ—è¡¨
        tasks = []
        for i, q_data in enumerate(generated_questions, 1):
            task = self._process_single_question_concurrently(
                question_data=q_data,
                doc_id=doc_id,
                subject=subject,
                question_index=i
            )
            tasks.append(task)

        # 2. ä½¿ç”¨ asyncio.gather ä¸€æ¬¡æ€§åŸ·è¡Œæ‰€æœ‰ä»»å‹™
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # 3. æ”¶é›†è™•ç†çµæœ
        saved_questions = []
        all_knowledge_points = set()
        failed_count = 0

        for result in results:
            if isinstance(result, Exception):
                print(f"ä¸€å€‹æ¨¡æ“¬é¡Œä»»å‹™åŸ·è¡Œæ™‚ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {result}")
                failed_count += 1
            elif result.get('success'):
                saved_questions.append(result)
                for kp in result.get('knowledge_points', []):
                    all_knowledge_points.add(kp.strip())
            else:
                print(f"ä¸€å€‹æ¨¡æ“¬é¡Œä»»å‹™è™•ç†å¤±æ•—: {result.get('error')}")
                failed_count += 1
        
        # ... (å¾ŒçºŒçš„æ‘˜è¦å’Œæ¸¬é©—è™•ç†ä¿æŒä¸è®Š) ...
        summary_raw_data = await self.gemini.generate_summary(content)
        # ... (è™•ç†æ‘˜è¦) ...

        quiz_data = await self.gemini.generate_quick_quiz(content, subject)
        # ... (è™•ç†æ¸¬é©—) ...

        message = f'å­¸ç¿’è³‡æ–™è™•ç†å®Œæˆï¼ç”Ÿæˆäº† {len(saved_questions)} é“æ¨¡æ“¬é¡Œ ({failed_count} é“å¤±æ•—)ã€‚'
        print(message)

        return {
            'success': True,
            'content_type': 'study_material',
            'subject': subject,
            'document_id': doc_id,
            'questions': saved_questions,
            'knowledge_points': list(all_knowledge_points),
            'summary': summary_data,
            'quiz': quiz_data,
            'message': message
        }
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Python
IGNORE_WHEN_COPYING_END
3. ç¸½çµèˆ‡é©—æ”¶æ¨™æº–

é‡æ§‹ç›®æ¨™ï¼šå°‡ _process_exam_content å’Œ _process_study_material å…©å€‹å‡½å¼ä¸­çš„ for è¿´åœˆæ”¹ç‚ºä½¿ç”¨ asyncio.gather çš„ä¸¦è¡Œæ¨¡å¼ã€‚

æ ¸å¿ƒæ”¹å‹•ï¼šæ–°å¢ _process_single_question_concurrently è¼”åŠ©å‡½å¼ï¼Œä¸¦åœ¨ä¸Šè¿°å…©å€‹ä¸»å‡½å¼ä¸­å‘¼å«å®ƒä¾†å»ºç«‹ä»»å‹™åˆ—è¡¨ã€‚

é©—æ”¶æ¨™æº–ï¼š

ç¨‹å¼ç¢¼æˆåŠŸåŸ·è¡Œï¼ŒåŠŸèƒ½èˆ‡é‡æ§‹å‰ä¸€è‡´ã€‚

è™•ç†åŒ…å«å¤šå€‹é¡Œç›®çš„æ–‡ä»¶æ™‚ï¼Œç¸½è€—æ™‚é¡¯è‘—ç¸®çŸ­ã€‚

ç³»çµ±æ—¥èªŒæ‡‰é¡¯ç¤ºé¡Œç›®æ˜¯ã€Œä¸¦è¡Œè™•ç†ã€çš„ï¼Œè€Œä¸æ˜¯å¾ªåºæ‰“å°è™•ç†æ—¥èªŒã€‚

å³ä½¿æœ‰å–®ä¸€é¡Œç›®è™•ç†å¤±æ•—ï¼Œä¹Ÿä¸æ‡‰ä¸­æ–·æ•´å€‹æµç¨‹ï¼Œå…¶ä»–æˆåŠŸçš„é¡Œç›®æ‡‰èƒ½æ­£å¸¸å„²å­˜ã€‚



# ä»¥ä¸‹æ”¹ç‰ˆè¨ˆç•«å…ˆå¿½è¦–
# Please disregard the following revision plan for now.

# Development Guide for AI Agents

This repository powers an AI-driven exam knowledge system. Follow the guidelines below when extending the project.

## Goal
Implement the knowledge graph visualization referenced in `REFACTORING_PLAN.md`. The `/knowledge-graph` route currently displays a placeholder. We need an interactive graph to show how knowledge points relate.

## Tasks
1. **Backend API**
   - Provide an endpoint (e.g., `/api/knowledge-graph`) returning JSON with `nodes` and `edges` representing knowledge points and their relationships.
   - Use existing database tables (`knowledge_points`, `question_knowledge_points` and related tables) to assemble the data. Add helper queries in `DatabaseManager` if required.

2. **Frontend Visualization**
   - Update `knowledge_graph.html` to render the graph using **D3.js** or **Cytoscape.js**.
   - Fetch the API data via AJAX and allow interactions such as zooming, panning and clicking nodes to reveal related questions or details.
   - Keep styling consistent with the current Bootstrap layout.

3. **Documentation**
   - Document setup steps for the knowledge graph feature in `README.md`.
   - Add any new dependencies to `requirements.txt`.

## General Guidelines
- Keep changes focused on the knowledge graph unless fixing small bugs encountered during development.
- Write modular Python functions with docstrings.
- Manual testing can be done by running `python web_app.py` and navigating to `/knowledge-graph`.
- Refer to `REFACTORING_PLAN.md` for broader context.
